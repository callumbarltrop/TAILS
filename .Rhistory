data = read.csv(file="ExampleDataset/dauphin_island_detren_declust.csv")
rm(list=ls())
#Load in helper functions and call required packages
source('Functions/helper_functions.R')
source('Functions/TailEQD.R')
thresh_select_function <- function(data, thresh, threshold_probabilities=NULL, baseline_probability,ppy,k = 100, m = 500,parallel = FALSE){
# Check inputs are valid
if (!is.numeric(data)) stop("data must be a vector")
if (!is.numeric(thresh)) stop("thresh to be tested needs to be a vector")
if (!is.numeric(threshold_probabilities) & !is.null(threshold_probabilities)) stop("threshold_probabilities need to be a vector or NULL")
if (!is.numeric(baseline_probability) | length(baseline_probability)!=1 | baseline_probability < 0 | baseline_probability > 1) stop("baseline_probability must be a single value between 0 and 1")
if (k <= 0 | k %% 1 != 0) stop("Number of bootstrapped samples (k) must be a positive integer")
if (m <= 0 | m %% 1 != 0) stop("Number of equally spaced probabilities (m) must be a positive integer")
if (!is.logical(parallel)) stop("parallel can only take the values 'TRUE' or 'FALSE'")
meandistances <- xis <- sigmas <- num_excess <- numeric(length(thresh))
#length of data
n = length(data)
if(is.null(threshold_probabilities)){
##### convert thresholds to empirical exceedance probabilities ######
# Create the empirical CDF from the data
ecdf_func <- ecdf(data)
# Evaluate the empirical CDF at the selected quantiles
threshold_probabilities <- ecdf_func(thresh)
}
#select probabilities of interest - from threshold event probability to an upper bound defined by sample size
##### linearly spaced
#This needs actioning - what do we select again? A 1 in 1 year event?
if (baseline_probability>1 - (10/n)) stop("Baseline event probability is too large for the given sample size. Please decrease.")
quantile_probs <- seq(baseline_probability,1 - (10/n),length=m)
for (i in 1:length(thresh)) { #for each threshold
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
if (threshold_probability <= 1 - (1/ppy)) { #We only fit the model if the threshold is less than the 1 in 1 year empirical return level
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
for (j in 1:k) { #for each bootstrap
X <- sample(excess, num_excess[i], replace = TRUE) #sample with replacement from the exceedences
mle <- mean(X)
ifelse(xis[i] < 0, pars_init <-  c(mle, 0.1) ,pars_init <- c(sigmas[i], xis[i]) )
gpd.fit <- optim(GPD_LL, z = X, par = pars_init, control = list(fnscale = -1)) #fit the gpd to the sample
############ using matched quantiles (from callum's code)
theoretical_quantiles <- qgpd(exceedance_probs[mask], scale = gpd.fit$par[[1]], shape = gpd.fit$par[[2]])
empirical_quants <- quantile(X,probs=exceedance_probs[mask]) #to get the empirical quantiles for this iteration
#find the errors between empirical and theoretical quantiles
errors <- abs(empirical_quants - theoretical_quantiles)
#calculate mean errors - EQD
distances[j] <- (1/length(errors)) * sum(errors) # errors over the threshold is inheriant in the quantile selection
}
meandistances[i] <- mean(distances) #find mean across all bootstraps
} else{
meandistances[i] <- NA
}
}
chosen_index <- which.min(meandistances)
chosen_threshold <- thresh[chosen_index]
chosen_threshold_prob <- threshold_probabilities[chosen_index]
xi <- xis[chosen_index]
sigma <- sigmas[chosen_index]
len <- num_excess[chosen_index]
####### use the data over the selected threshold and test the goodness of fit use the anderson-darling test
data_over_u <- data[data > chosen_threshold]-chosen_threshold
result <- list(
thresh = chosen_threshold,
threshold_prob = chosen_threshold_prob,
par = c(sigma,xi),
num_excess = len,
dists = meandistances
)
return(result)
}
rm(list=ls())
#Load in helper functions and call required packages
source('Functions/helper_functions.R')
source('Functions/TailEQD.R')
#We load in an example sea level data set from Dauphin Island, Alabama
data = read.csv(file="ExampleDataset/dauphin_island_detren_declust.csv")
#Extract sea level
data = data$sea_level
#Specify non-exceedance quantile probabilities at which to define thresholds
threshold_probabilities = seq(0.5,0.999,by=0.001)
#Evaluate empricial quantiles from data
thresholds = unname(quantile(data,probs = threshold_probabilities))
#Specify length of data (in years)
record_length = 40.42
#Specify baseline event return period. We recommend keeping this value fixed at 0.25 years
baseline_event_RP = 0.25
#Compute the number of observations observed each year (on average)
points_per_year = length(data)/record_length
#Compute non-exceedance probability corresponding to the baseline event
baseline_probability = 1-1/(baseline_event_RP*points_per_year)
points_per_year
thresh_select_function <- function(data, thresh, threshold_probabilities=NULL, baseline_probability,ppy,k = 100, m = 500,parallel = FALSE){
# Check inputs are valid
if (!is.numeric(data)) stop("data must be a vector")
if (!is.numeric(thresh)) stop("thresh to be tested needs to be a vector")
if (!is.numeric(threshold_probabilities) & !is.null(threshold_probabilities)) stop("threshold_probabilities need to be a vector or NULL")
if (!is.numeric(baseline_probability) | length(baseline_probability)!=1 | baseline_probability < 0 | baseline_probability > 1) stop("baseline_probability must be a single value between 0 and 1")
if (k <= 0 | k %% 1 != 0) stop("Number of bootstrapped samples (k) must be a positive integer")
if (m <= 0 | m %% 1 != 0) stop("Number of equally spaced probabilities (m) must be a positive integer")
if (!is.numeric(ppy) | length(ppy) != 1) stop("ppy must be a single numeric value")
if (!is.logical(parallel)) stop("parallel can only take the values 'TRUE' or 'FALSE'")
meandistances <- xis <- sigmas <- num_excess <- numeric(length(thresh))
#length of data
n = length(data)
if(is.null(threshold_probabilities)){
##### convert thresholds to empirical exceedance probabilities ######
# Create the empirical CDF from the data
ecdf_func <- ecdf(data)
# Evaluate the empirical CDF at the selected quantiles
threshold_probabilities <- ecdf_func(thresh)
}
#select probabilities of interest
if (baseline_probability>1 - (1/ppy)) stop("Baseline event probability is too large for the given sample size. Please decrease.")
quantile_probs <- seq(baseline_probability,1 - (1/ppy),length=m)
for (i in 1:length(thresh)) { #for each threshold
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
if (threshold_probability <= 1 - (1/ppy)) { #We only fit the model if the threshold is less than the 1 in 1 year empirical return level
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
for (j in 1:k) { #for each bootstrap
X <- sample(excess, num_excess[i], replace = TRUE) #sample with replacement from the exceedences
mle <- mean(X)
ifelse(xis[i] < 0, pars_init <-  c(mle, 0.1) ,pars_init <- c(sigmas[i], xis[i]) )
gpd.fit <- optim(GPD_LL, z = X, par = pars_init, control = list(fnscale = -1)) #fit the gpd to the sample
############ using matched quantiles (from callum's code)
theoretical_quantiles <- qgpd(exceedance_probs[mask], scale = gpd.fit$par[[1]], shape = gpd.fit$par[[2]])
empirical_quants <- quantile(X,probs=exceedance_probs[mask]) #to get the empirical quantiles for this iteration
#find the errors between empirical and theoretical quantiles
errors <- abs(empirical_quants - theoretical_quantiles)
#calculate mean errors - EQD
distances[j] <- (1/length(errors)) * sum(errors) # errors over the threshold is inheriant in the quantile selection
}
meandistances[i] <- mean(distances) #find mean across all bootstraps
} else{
meandistances[i] <- NA
}
}
chosen_index <- which.min(meandistances)
chosen_threshold <- thresh[chosen_index]
chosen_threshold_prob <- threshold_probabilities[chosen_index]
xi <- xis[chosen_index]
sigma <- sigmas[chosen_index]
len <- num_excess[chosen_index]
####### use the data over the selected threshold and test the goodness of fit use the anderson-darling test
data_over_u <- data[data > chosen_threshold]-chosen_threshold
result <- list(
thresh = chosen_threshold,
threshold_prob = chosen_threshold_prob,
par = c(sigma,xi),
num_excess = len,
dists = meandistances
)
return(result)
}
thresh_select = thresh_select_function(data = data,thresh = thresholds,threshold_probabilities = threshold_probabilities,baseline_probability = baseline_probability,ppy=points_per_year,k=200)
plot(thresholds,thresh_select$dists,xlim=c(min(thresholds),max(thresholds[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=thresh_select$thresh,lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=threshold_probabilities[which.min(thresh_select$dists)],lwd=4,col=2)
thresh_select = thresh_select_function(data = data,thresh = thresholds,threshold_probabilities = threshold_probabilities,baseline_probability = baseline_probability,ppy=points_per_year,k=200)
plot(thresholds,thresh_select$dists,xlim=c(min(thresholds),max(thresholds[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=thresh_select$thresh,lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=threshold_probabilities[which.min(thresh_select$dists)],lwd=4,col=2)
data_over_u = data[data > thresh_select$thresh]-thresh_select$thresh
m = length(data_over_u)
observed_quants = sort(data_over_u)
theoretical_quants = qgpd((1:m)/(m+1),shape=thresh_select$par[2],scale = thresh_select$par[1])
plot(theoretical_quants,observed_quants,xlim=range(theoretical_quants,observed_quants),
ylim=range(theoretical_quants,observed_quants),pch=16,col=1,ylab="Empirical",xlab="Model",
cex.lab=1.3, cex.axis=1.2,cex.main=1.8, cex=0.5)
abline(a=0,b=1,lwd=3,col=2)
points(theoretical_quants,observed_quants,pch=16,col=1, cex=1)
plot(thresholds,thresh_select$dists,xlim=c(min(thresholds),max(thresholds[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=thresh_select$thresh,lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=threshold_probabilities[which.min(thresh_select$dists)],lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
baseline_probability
1 - (1/ppy)
ppy = points_per_year
1 - (1/ppy)
thresh_select_function <- function(data, thresh, threshold_probabilities=NULL, baseline_probability,ppy,k = 100, m = 500,parallel = FALSE){
# Check inputs are valid
if (!is.numeric(data)) stop("data must be a vector")
if (!is.numeric(thresh)) stop("thresh to be tested needs to be a vector")
if (!is.numeric(threshold_probabilities) & !is.null(threshold_probabilities)) stop("threshold_probabilities need to be a vector or NULL")
if (!is.numeric(baseline_probability) | length(baseline_probability)!=1 | baseline_probability < 0 | baseline_probability > 1) stop("baseline_probability must be a single value between 0 and 1")
if (k <= 0 | k %% 1 != 0) stop("Number of bootstrapped samples (k) must be a positive integer")
if (m <= 0 | m %% 1 != 0) stop("Number of equally spaced probabilities (m) must be a positive integer")
if (!is.numeric(ppy) | length(ppy) != 1) stop("ppy must be a single numeric value")
if (!is.logical(parallel)) stop("parallel can only take the values 'TRUE' or 'FALSE'")
meandistances <- xis <- sigmas <- num_excess <- numeric(length(thresh))
#length of data
n = length(data)
if(is.null(threshold_probabilities)){
##### convert thresholds to empirical exceedance probabilities ######
# Create the empirical CDF from the data
ecdf_func <- ecdf(data)
# Evaluate the empirical CDF at the selected quantiles
threshold_probabilities <- ecdf_func(thresh)
}
#select probabilities of interest
if (baseline_probability>1 - (1/ppy)) stop("Baseline event probability is too large - please decrease.")
# quantile_probs <- seq(baseline_probability,1 - (1/ppy),length=m)
quantile_probs <- seq(baseline_probability,1 - (10/n),length=m)
for (i in 1:length(thresh)) { #for each threshold
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
if (threshold_probability <= 1 - (1/ppy)) { #We only fit the model if the threshold is less than the 1 in 1 year empirical return level
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
for (j in 1:k) { #for each bootstrap
X <- sample(excess, num_excess[i], replace = TRUE) #sample with replacement from the exceedences
mle <- mean(X)
ifelse(xis[i] < 0, pars_init <-  c(mle, 0.1) ,pars_init <- c(sigmas[i], xis[i]) )
gpd.fit <- optim(GPD_LL, z = X, par = pars_init, control = list(fnscale = -1)) #fit the gpd to the sample
############ using matched quantiles (from callum's code)
theoretical_quantiles <- qgpd(exceedance_probs[mask], scale = gpd.fit$par[[1]], shape = gpd.fit$par[[2]])
empirical_quants <- quantile(X,probs=exceedance_probs[mask]) #to get the empirical quantiles for this iteration
#find the errors between empirical and theoretical quantiles
errors <- abs(empirical_quants - theoretical_quantiles)
#calculate mean errors - EQD
distances[j] <- (1/length(errors)) * sum(errors) # errors over the threshold is inheriant in the quantile selection
}
meandistances[i] <- mean(distances) #find mean across all bootstraps
} else{
meandistances[i] <- NA
}
}
chosen_index <- which.min(meandistances)
chosen_threshold <- thresh[chosen_index]
chosen_threshold_prob <- threshold_probabilities[chosen_index]
xi <- xis[chosen_index]
sigma <- sigmas[chosen_index]
len <- num_excess[chosen_index]
####### use the data over the selected threshold and test the goodness of fit use the anderson-darling test
data_over_u <- data[data > chosen_threshold]-chosen_threshold
result <- list(
thresh = chosen_threshold,
threshold_prob = chosen_threshold_prob,
par = c(sigma,xi),
num_excess = len,
dists = meandistances
)
return(result)
}
thresh_select = thresh_select_function(data = data,thresh = thresholds,threshold_probabilities = threshold_probabilities,baseline_probability = baseline_probability,ppy=points_per_year,k=100)
plot(thresholds,thresh_select$dists,xlim=c(min(thresholds),max(thresholds[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=thresh_select$thresh,lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=threshold_probabilities[which.min(thresh_select$dists)],lwd=4,col=2)
points_per_year
ppy=points_per_year
k=100
thresh = thresholds
m = 500
# Check inputs are valid
if (!is.numeric(data)) stop("data must be a vector")
if (!is.numeric(thresh)) stop("thresh to be tested needs to be a vector")
if (!is.numeric(threshold_probabilities) & !is.null(threshold_probabilities)) stop("threshold_probabilities need to be a vector or NULL")
if (!is.numeric(baseline_probability) | length(baseline_probability)!=1 | baseline_probability < 0 | baseline_probability > 1) stop("baseline_probability must be a single value between 0 and 1")
if (k <= 0 | k %% 1 != 0) stop("Number of bootstrapped samples (k) must be a positive integer")
if (m <= 0 | m %% 1 != 0) stop("Number of equally spaced probabilities (m) must be a positive integer")
if (!is.numeric(ppy) | length(ppy) != 1) stop("ppy must be a single numeric value")
if (!is.logical(parallel)) stop("parallel can only take the values 'TRUE' or 'FALSE'")
meandistances <- xis <- sigmas <- num_excess <- numeric(length(thresh))
#length of data
n = length(data)
if(is.null(threshold_probabilities)){
##### convert thresholds to empirical exceedance probabilities ######
# Create the empirical CDF from the data
ecdf_func <- ecdf(data)
# Evaluate the empirical CDF at the selected quantiles
threshold_probabilities <- ecdf_func(thresh)
}
baseline_probability
1 - (1/ppy)
#select probabilities of interest
if (baseline_probability>1 - (1/ppy)) stop("Baseline event probability is too large - please decrease.")
quantile_probs <- seq(baseline_probability,1 - (1/ppy),length=m)
quantile_probs
for (i in 1:length(thresh)) { #for each threshold
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
if (threshold_probability <= 1 - (1/ppy)) { #We only fit the model if the threshold is less than the 1 in 1 year empirical return level
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
for (j in 1:k) { #for each bootstrap
X <- sample(excess, num_excess[i], replace = TRUE) #sample with replacement from the exceedences
mle <- mean(X)
ifelse(xis[i] < 0, pars_init <-  c(mle, 0.1) ,pars_init <- c(sigmas[i], xis[i]) )
gpd.fit <- optim(GPD_LL, z = X, par = pars_init, control = list(fnscale = -1)) #fit the gpd to the sample
############ using matched quantiles (from callum's code)
theoretical_quantiles <- qgpd(exceedance_probs[mask], scale = gpd.fit$par[[1]], shape = gpd.fit$par[[2]])
empirical_quants <- quantile(X,probs=exceedance_probs[mask]) #to get the empirical quantiles for this iteration
#find the errors between empirical and theoretical quantiles
errors <- abs(empirical_quants - theoretical_quantiles)
#calculate mean errors - EQD
distances[j] <- (1/length(errors)) * sum(errors) # errors over the threshold is inheriant in the quantile selection
}
meandistances[i] <- mean(distances) #find mean across all bootstraps
} else{
meandistances[i] <- NA
}
}
chosen_index <- which.min(meandistances)
chosen_threshold <- thresh[chosen_index]
chosen_threshold_prob <- threshold_probabilities[chosen_index]
xi <- xis[chosen_index]
sigma <- sigmas[chosen_index]
len <- num_excess[chosen_index]
plot(thresh,meandistances)
plot(threshold_probabilities,meandistances)
plot(thresh,meandistances)
max(thresh)
max(threshold_probabilities)
max(threshold_probabilities[!is.na(meandistances)])
c = max(threshold_probabilities[!is.na(meandistances)])
1 - 1/ppy
which.min(meandistances)
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
threshold_probability
thresh[i]
length(excess)
meandistances
which.min(meandistances)
i = 493
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
threshold_probability
num_excess[i]
threshold_probability
1 - (1/ppy)
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
init.fit
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
mask
sum(mask)
i = order(meandistances,decreasing = F)
order(meandistances,decreasing = F)
i = 469
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
num_excess[i]
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
mask
sum(mask)
#Checking for required packages. This function will install any required packages if they are not already installed
packages = c("parallel")
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
thresh_select_function <- function(data, thresh, threshold_probabilities=NULL, baseline_probability,ppy,k = 100, m = 500,parallel = FALSE){
# Check inputs are valid
if (!is.numeric(data)) stop("data must be a vector")
if (!is.numeric(thresh)) stop("thresh to be tested needs to be a vector")
if (!is.numeric(threshold_probabilities) & !is.null(threshold_probabilities)) stop("threshold_probabilities need to be a vector or NULL")
if (!is.numeric(baseline_probability) | length(baseline_probability)!=1 | baseline_probability < 0 | baseline_probability > 1) stop("baseline_probability must be a single value between 0 and 1")
if (k <= 0 | k %% 1 != 0) stop("Number of bootstrapped samples (k) must be a positive integer")
if (m <= 0 | m %% 1 != 0) stop("Number of equally spaced probabilities (m) must be a positive integer")
if (!is.numeric(ppy) | length(ppy) != 1) stop("ppy must be a single numeric value")
if (!is.logical(parallel)) stop("parallel can only take the values 'TRUE' or 'FALSE'")
meandistances <- xis <- sigmas <- num_excess <- numeric(length(thresh))
#length of data
n = length(data)
if(is.null(threshold_probabilities)){
##### convert thresholds to empirical exceedance probabilities ######
# Create the empirical CDF from the data
ecdf_func <- ecdf(data)
# Evaluate the empirical CDF at the selected quantiles
threshold_probabilities <- ecdf_func(thresh)
}
#select probabilities of interest
if (baseline_probability>1 - (1/ppy)) stop("Baseline event probability is too large - please decrease.")
quantile_probs <- seq(baseline_probability,1 - (1/ppy),length=m)
# quantile_probs <- seq(baseline_probability,1 - (10/n),length=m)
for (i in 1:length(thresh)) { #for each threshold
u <- thresh[i] #select threshold
excess <- data[data > u] - u #exceedences over threshold
num_excess[i] <- length(excess) #number of exceedences over threshold
threshold_probability <- threshold_probabilities[i] #probability of the threshold compared to the empirical distribution
if (threshold_probability <= 1 - (1/ppy) ) { #We only fit the model if the threshold is less than the 1 in 1 year empirical return level
mle0 <- mean(excess)
init.fit <- optim(GPD_LL, z = excess, par = c(mle0,0.1), control = list(fnscale = -1))
xis[i] <- init.fit$par[[2]]
sigmas[i] <- init.fit$par[[1]]
distances <- numeric(k)
#computing theoretical quantiles. This remains constant over bootstrapping
exceedance_probs <- 1 - (1-quantile_probs)/(1-threshold_probability)
# mask to remove any exceedance probabilities that are less than 0 or equal to 1 (i.e., not valid)
# note that this accounts for the cases when the baseline event is lower than the threshold - we just estimate quantiles above the threshold in t
mask <- exceedance_probs > 0 & exceedance_probs < 1
#I have adapted the code here - it only makes sense to compute the metric when we are evaluating over a certain number of probabilities
if(sum(mask) < 50){meandistances[i] <- NA} else {
for (j in 1:k) { #for each bootstrap
X <- sample(excess, num_excess[i], replace = TRUE) #sample with replacement from the exceedences
mle <- mean(X)
ifelse(xis[i] < 0, pars_init <-  c(mle, 0.1) ,pars_init <- c(sigmas[i], xis[i]) )
gpd.fit <- optim(GPD_LL, z = X, par = pars_init, control = list(fnscale = -1)) #fit the gpd to the sample
############ using matched quantiles (from callum's code)
theoretical_quantiles <- qgpd(exceedance_probs[mask], scale = gpd.fit$par[[1]], shape = gpd.fit$par[[2]])
empirical_quants <- quantile(X,probs=exceedance_probs[mask]) #to get the empirical quantiles for this iteration
#find the errors between empirical and theoretical quantiles
errors <- abs(empirical_quants - theoretical_quantiles)
#calculate mean errors - EQD
distances[j] <- (1/length(errors)) * sum(errors) # errors over the threshold is inheriant in the quantile selection
}
meandistances[i] <- mean(distances) #find mean across all bootstraps
}
} else{
meandistances[i] <- NA
}
}
chosen_index <- which.min(meandistances)
chosen_threshold <- thresh[chosen_index]
chosen_threshold_prob <- threshold_probabilities[chosen_index]
xi <- xis[chosen_index]
sigma <- sigmas[chosen_index]
len <- num_excess[chosen_index]
####### use the data over the selected threshold and test the goodness of fit use the anderson-darling test
data_over_u <- data[data > chosen_threshold]-chosen_threshold
result <- list(
thresh = chosen_threshold,
threshold_prob = chosen_threshold_prob,
par = c(sigma,xi),
num_excess = len,
dists = meandistances
)
return(result)
}
thresh_select = thresh_select_function(data = data,thresh = thresholds,threshold_probabilities = threshold_probabilities,baseline_probability = baseline_probability,ppy=points_per_year,k=100)
plot(thresholds,thresh_select$dists,xlim=c(min(thresholds),max(thresholds[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=thresh_select$thresh,lwd=4,col=2)
plot(threshold_probabilities,thresh_select$dists,xlim=c(min(threshold_probabilities),max(threshold_probabilities[!is.na(thresh_select$dists)])),type="l",lwd=3,col="grey",xlab="Threshold",ylab="Tail EQD",main="Updated threshold selection",cex.lab=1.5, cex.axis=1.5, cex.main=1.5)
abline(v=threshold_probabilities[which.min(thresh_select$dists)],lwd=4,col=2)
